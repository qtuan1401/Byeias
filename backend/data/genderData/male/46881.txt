’’ ’’ ’’ ’The incident and resulting controversy points to a broader truth: Facebook is becoming more and more like a traditional media company, and it needs to embrace the thorny issues that come with the territory.’ ”There may not be guidelines telling curators not to select certain topics, but people have implicit biases. It’s natural and, to an extent, unsurprising. Curators will necessarily pick topics that they know about and frame them in a way that is reflective of their mindset.  (emphasis ours):” ’This is precisely what happens in any media organization: Writers and editors gravitate toward subjects of interest  —   and the combined weight of these biases give the organizations their (deliberate or otherwise) slant, from the   Guardian to the populist Daily Mail.’ ”The big difference is that Facebook doesn’t frame itself as a media company  —   and generally tries to avoid the necessary debates about bias and slant that media companies have to tackle. Facebook’s Trending section is presented as a neutral reflection of organically popular stories on the site: I’d wager that many Facebook users don’t even realize there are human curators.” ’ these problems are catching up with the social network.’ ’”Facebook routinely says that it doesn’’t see itself as a media entity,” Ingram wrote, ”and doesn’’t see its algorithmic choices as being of any concern to anyone outside the company  —   even when those choices help influence the way people think and behave, like whether they decide to vote and how they see political issues . .. At some point, however, Facebook is going to have to grapple with these kinds of issues, or at least acknowledge that they exist and that people have a right to be concerned about them. ”’ ’One potential remedy is to introduce what newspapers and media organizations have had for decades: bylines and mastheads.’ ”The vast, vast majority of the media business credits authors and producers as well as the organization’s editorial leadership. This allows for public accountability. Sure, the writer might be biased  —   and many writers embrace their biases, arguing against the falseness of forced neutrality  —   but the byline means there is editorial accountability.” ”If Facebook adopted an optional masthead that showed who has curated topics, and which editors were online, it wouldn’t solve the problem of unconscious biases. But it would alert users to them, allowing them to be better informed. It would be an acknowledgement that, yes, the social network is grappling with these issues, and it’s owning up to that.” ’To do so, however, would require Facebook to embrace its role and responsibility as a dominant media organization to a degree that is has previously shown no inclination to do. ”’ ’And even if it did, it might only be a temporary fix; almost all of the former Facebook curators Gizmodo talked to  ”they were there not to work, but to serve as training modules for Facebook’’s algorithm. ”’ ”In short: It’s only a matter of time until the curators are replaced by opaque algorithms  —   and we are once again none the wiser as to how the most powerful media company in the world decides what to show us.” ’’ ”Facebook’s vice president of search Dan Stocky. ..”