{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AddedDllDirectory('C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2/bin')>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "os.add_dll_directory(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2/bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sam's PC\\AppData\\Local\\Temp\\ipykernel_24404\\3817716175.py:3: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    }
   ],
   "source": [
    "path = r\"..\\data\\KAGGLE\\kaggle_finalised.csv\"\n",
    "df = pd.read_csv(path, usecols=[\"source\",\"labels\",\"headline\",\"text\"])\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "x_train, x_test = train_test_split(df, test_size=0.2, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    5764\n",
       " 1    1297\n",
       "-1    1120\n",
       " 2    633 \n",
       "-2    529 \n",
       " 3    158 \n",
       "-3    119 \n",
       " 4    63  \n",
       "-4    30  \n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swingdata = df['labels'].unique()\n",
    "class_weights = list(class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(df['labels']), y=swingdata))\n",
    "np.unique(df['labels'])\n",
    "class_weights.sort()\n",
    "df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights={}\n",
    "\n",
    "for index, weight in enumerate(class_weights):\n",
    "    weights[index]=weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = tf.data.Dataset.from_tensor_slices((x_train['text'].values, x_train['labels'].values))\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((x_test['text'].values, x_test['labels'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(text, labels):\n",
    "    return text, tf.one_hot(labels, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_f=dataset_train.map(fetch)\n",
    "test_data_f=dataset_test.map(fetch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = next(iter(train_data_f.batch(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 128), dtype=float32, numpy=\n",
       "array([[ 1.5701346e+00,  5.7551455e-01, -9.1829829e-02, -2.9152185e-01,\n",
       "        -2.1295413e-01, -2.9568093e-02,  1.7536528e-02, -2.3557460e-01,\n",
       "        -6.8924934e-02,  8.6796895e-02,  4.0287706e-01,  4.0075305e-01,\n",
       "        -1.5786774e-01,  2.0713823e-01, -2.3699395e-01,  1.4814676e-01,\n",
       "        -4.6862227e-01, -2.1087460e-01, -9.7300753e-02,  1.7832458e+00,\n",
       "         1.2497991e-01,  4.1937110e-01, -1.2303090e-01,  9.2001259e-02,\n",
       "        -9.6788570e-02,  1.7181440e-01,  3.9333358e-01, -5.9749130e-02,\n",
       "        -8.4132716e-02, -9.5848618e-03, -2.4290852e-01, -1.7437834e-01,\n",
       "         2.0996188e-01, -2.3239635e-02,  1.5073279e-01,  1.9917414e-01,\n",
       "         8.2096960e-03, -2.6212114e-01, -1.7529175e-01, -1.8709232e-01,\n",
       "         1.2903674e-01, -3.4300316e-02, -1.8365154e-01,  3.5388574e-01,\n",
       "         1.9681220e-01, -1.3587591e-01, -8.1963144e-02, -1.6614601e-01,\n",
       "        -8.1249990e-02, -2.7942288e-01, -9.5973194e-02,  9.2167236e-02,\n",
       "         3.0277950e-01, -1.2845042e-01, -1.7444688e-01, -9.9810340e-02,\n",
       "        -1.3174242e-01,  1.9206706e-01, -1.4189649e-02, -2.1810600e-01,\n",
       "        -2.9532424e-01, -1.3065572e-01, -2.9205754e-01, -6.9282092e-02,\n",
       "         1.5403193e-01,  3.0968156e-01,  2.1560866e-01, -4.0112965e-02,\n",
       "         8.6493157e-03, -2.5041255e-01,  5.6224391e-02, -7.7227056e-02,\n",
       "        -3.6872350e-02,  6.6871151e-02,  1.1541492e-02,  4.1777596e-01,\n",
       "        -7.4953564e-02, -2.1801730e-01,  4.4608381e-02, -2.2729436e-01,\n",
       "         4.2141750e-02, -3.0402997e-01, -3.7576520e-01,  1.4620385e-01,\n",
       "        -2.3520751e-04, -1.0156152e-02, -4.0573290e-01, -1.8697143e-02,\n",
       "         6.4910960e-01,  6.1583763e-01,  1.1712871e-01,  2.5503683e-01,\n",
       "         1.2129097e-01, -2.4721071e-01,  1.5188588e-01, -6.8917550e-02,\n",
       "         2.9907131e-01,  3.5596073e-02, -6.3592821e-01,  4.1006599e-02,\n",
       "        -6.7957900e-02,  2.9984862e-02, -8.7481029e-02,  2.0254503e-01,\n",
       "        -2.9834151e-02,  1.1091273e-01,  3.3920327e-01,  2.2460622e-01,\n",
       "         2.8336722e-01,  1.5050724e-02, -6.0052782e-01, -2.3676535e-01,\n",
       "         6.7998633e-02, -4.4608954e-01,  4.0120485e-01, -2.4584128e-01,\n",
       "         2.7539405e-01,  2.1599217e-01,  2.4162756e-01,  5.1570779e-01,\n",
       "         2.7066070e-01, -2.1722728e-01,  1.8729526e-01,  4.1086170e-01,\n",
       "        -1.7642926e-01, -1.9605818e-01,  1.1097205e-01, -3.9767090e-02]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = \"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\"\n",
    "hub_layer = hub.KerasLayer(embedding, output_shape=[128], input_shape=[], dtype=tf.string, trainable=True)\n",
    "hub_layer(train_data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 128)               124642688 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              129000    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 500)               500500    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 120)               60120     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 120)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 9)                 1089      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 125,333,397\n",
      "Trainable params: 125,333,397\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "#model.add(hub_layer)\n",
    "#for units in [128, 128, 64, 32]:\n",
    "#    model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
    "#    model.add(tf.keras.layers.Dropout(0.4))\n",
    "#model.add(tf.keras.layers.Dense(9, activation=\"softmax\"))\n",
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(1000,activation=tf.nn.sigmoid))\n",
    "model.add(tf.keras.layers.Dropout(0.5, noise_shape=None, seed=None))\n",
    "model.add(tf.keras.layers.Dense(500,activation=tf.nn.sigmoid))\n",
    "model.add(tf.keras.layers.Dropout(0.5, noise_shape=None, seed=None))\n",
    "model.add(tf.keras.layers.Dense(120,activation=tf.nn.sigmoid))\n",
    "model.add(tf.keras.layers.Dropout(0.5, noise_shape=None, seed=None))\n",
    "model.add(tf.keras.layers.Dense(9,activation=tf.nn.softmax))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_f=train_data_f.shuffle(70000).batch(512)\n",
    "test_data_f=test_data_f.batch(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sam's PC\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\backend.py:5531: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 6s 213ms/step - loss: 1.0160 - accuracy: 0.6506 - val_loss: 0.7209 - val_accuracy: 0.7854\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8812 - accuracy: 0.7394 - val_loss: 0.7643 - val_accuracy: 0.7854\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 3s 205ms/step - loss: 0.8748 - accuracy: 0.7347 - val_loss: 0.7318 - val_accuracy: 0.7854\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.8571 - accuracy: 0.7288 - val_loss: 0.7237 - val_accuracy: 0.7854\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.8621 - accuracy: 0.7323 - val_loss: 0.7169 - val_accuracy: 0.7854\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.8632 - accuracy: 0.7278 - val_loss: 0.7096 - val_accuracy: 0.7854\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 0.8527 - accuracy: 0.7323 - val_loss: 0.6849 - val_accuracy: 0.7854\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 3s 199ms/step - loss: 0.8054 - accuracy: 0.7344 - val_loss: 0.6573 - val_accuracy: 0.7854\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.7810 - accuracy: 0.7290 - val_loss: 0.6322 - val_accuracy: 0.7854\n",
      "Epoch 10/15\n",
      "16/16 [==============================] - 3s 206ms/step - loss: 0.7376 - accuracy: 0.7234 - val_loss: 0.6180 - val_accuracy: 0.7854\n",
      "Epoch 11/15\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.7248 - accuracy: 0.7306 - val_loss: 0.6126 - val_accuracy: 0.7854\n",
      "Epoch 12/15\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.7015 - accuracy: 0.7265 - val_loss: 0.6068 - val_accuracy: 0.7854\n",
      "Epoch 13/15\n",
      "16/16 [==============================] - 3s 201ms/step - loss: 0.6693 - accuracy: 0.7290 - val_loss: 0.6111 - val_accuracy: 0.7854\n",
      "Epoch 14/15\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.6456 - accuracy: 0.7260 - val_loss: 0.6227 - val_accuracy: 0.7509\n",
      "Epoch 15/15\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.6310 - accuracy: 0.7328 - val_loss: 0.6302 - val_accuracy: 0.7586\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data_f,\n",
    "    epochs=15,\n",
    "    validation_data=test_data_f,\n",
    "    verbose=1,\n",
    "    class_weight=weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 76ms/step - loss: 0.6302 - accuracy: 0.7586\n",
      "Loss:  0.6301569938659668\n",
      "Accuracy:  0.7586206793785095\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_data_f)\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6405ec6159b0547165700ce207a2b1c9d048e435bca4e5d6f2cd71ef647b6574"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
